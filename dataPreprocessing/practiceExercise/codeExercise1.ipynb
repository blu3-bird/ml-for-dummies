{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cce5293d",
   "metadata": {},
   "source": [
    "### Data Preprocessing Exercies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ae4a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the libraries we need for data preprocessing\n",
    "import pandas as pd  # pandas: helps us work with data in tables (like Excel)\n",
    "import numpy as np  # numpy: helps us do mathematical operations on data\n",
    "from sklearn.compose import ColumnTransformer  # ColumnTransformer: applies different transformations to different columns\n",
    "from sklearn.impute import SimpleImputer  # SimpleImputer: fills in missing values with a strategy (like average)\n",
    "from sklearn.model_selection import train_test_split  # train_test_split: splits our data into training and testing sets\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler  # OneHotEncoder: converts text categories to numbers, LabelEncoder: converts labels to numbers, StandardScaler: scales numbers to similar ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784727a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the dataset:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>PropertyArea</th>\n",
       "      <th>LoanApproved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>680.0</td>\n",
       "      <td>Semiurban</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rural</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>690.0</td>\n",
       "      <td>Semiurban</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID  Gender Married  ... CreditScore  PropertyArea  LoanApproved\n",
       "0         101    Male     Yes  ...       720.0         Urban           Yes\n",
       "1         102  Female     Yes  ...       680.0     Semiurban           Yes\n",
       "2         103    Male      No  ...         NaN         Rural            No\n",
       "3         104    Male     Yes  ...       750.0         Urban           Yes\n",
       "4         105  Female     NaN  ...       690.0     Semiurban           Yes\n",
       "\n",
       "[5 rows x 9 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset (the .csv file) into a pandas DataFrame (table format)\n",
    "df = pd.read_csv('loan.csv')  # Read the loan.csv file from disk\n",
    "print(f'Loading the dataset:\\n')  # Print a message to show what we're doing\n",
    "df.head()  # Show the first 5 rows of the data to see what it looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db9b6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the features (X) from the target/label (y)\n",
    "# X = all columns except the first (ID) and last (target) columns - these are the input features\n",
    "# y = only the last column - this is what we want to predict (the target)\n",
    "X = df.iloc[:,1:-1].values  # Get all rows, columns from 1 to the second-to-last column\n",
    "y = df.iloc[:,-1].values  # Get all rows, only the last column (our target to predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a5b3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which columns are categorical (text/categories) and which are numerical (numbers)\n",
    "# This helps us know how to process each type of data differently\n",
    "categorical_columns = ['Gender', 'Married', 'Education', 'PropertyArea']  # Text columns that represent categories\n",
    "numerical_columns = ['Income', 'LoanAmount', 'CreditScore']  # Numerical columns with actual numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e75492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data in each column:\n",
      " CustomerID      0\n",
      "Gender          1\n",
      "Married         2\n",
      "Education       0\n",
      "Income          2\n",
      "LoanAmount      2\n",
      "CreditScore     2\n",
      "PropertyArea    0\n",
      "LoanApproved    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Handle missing data - fill in the empty values in our dataset\n",
    "missing_data = df.isnull().sum()  # Count how many missing values are in each column\n",
    "print(f'Missing data in each column:\\n {missing_data}')  # Show the count of missing values\n",
    "\n",
    "# Use SimpleImputer to fill missing numerical values with their average\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')  # Create an imputer that uses the mean (average)\n",
    "X[:,3:6] = imputer.fit_transform(X[:,3:6])  # Fill missing values in columns 3-5 with their average\n",
    "\n",
    "# Use SimpleImputer to fill missing categorical values with the most frequent value\n",
    "impute = SimpleImputer(missing_values=np.nan, strategy='most_frequent')  # Create an imputer that uses the most common value\n",
    "X[:,0:1] = impute.fit_transform(X[:,0:1])  # Fill missing values in column 0 with the most frequent value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9088e73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical text features into numerical format so machine learning models can understand them\n",
    "# ColumnTransformer applies different transformations to different columns\n",
    "ct = ColumnTransformer(transformers=[('arson',OneHotEncoder(),[0,1,2,6])],remainder='passthrough')  # OneHotEncoder converts categories (like \"Male\"/\"Female\") into 0s and 1s\n",
    "X = np.array(ct.fit_transform(X))  # Apply the transformation and convert to numpy array\n",
    "\n",
    "# Convert the target labels (y) from text to numbers using LabelEncoder\n",
    "le = LabelEncoder()  # Create a label encoder\n",
    "y = le.fit_transform(y)  # Transform labels like \"Yes\"/\"No\" into 0/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d123723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "# Training set: used to teach the machine learning model (80% of data)\n",
    "# Testing set: used to test how well the model learned (20% of data)\n",
    "X_train, X_test , y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=7)  # Split data: 80% train, 20% test; random_state=7 ensures reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a8ff0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale/normalize the numerical features so they are on a similar scale\n",
    "# This helps machine learning models work better (e.g., making values between -1 and 1)\n",
    "sc = StandardScaler()  # Create a scaler that will standardize the values\n",
    "X_train[:,10:] = sc.fit_transform(X_train[:,10:])  # Scale columns 10 onwards in training data and learn the scaling parameters\n",
    "\n",
    "# Apply the same scaling to the test data using the parameters learned from training data\n",
    "X_test[:,10:] = sc.transform(X_test[:,10:])  # Scale the test data using the same parameters (important: don't fit on test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c6fe6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      " [[0.0 1.0 1.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 -1.2543801660254887\n",
      "  -1.0908012177934066 -0.288225028525472]\n",
      " [0.0 1.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 1.0 2.0548780384093366\n",
      "  2.1464152995289614 1.765850283935534]\n",
      " [0.0 1.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0 1.0 0.1817130170311336\n",
      "  0.03518713605785183 0.19508680970064743]\n",
      " [1.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 1.0 0.0 -0.2553588212904471\n",
      "  -0.24630995240496278 -0.5902949274167958]\n",
      " [0.0 1.0 1.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 -0.1592990766043854\n",
      "  -0.9500526735619993 -2.1610584016516823]\n",
      " [1.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 1.0 0.0 -0.3177976553363872\n",
      "  -0.3870584966363701 -0.7866403616961566]\n",
      " [0.0 1.0 0.0 1.0 0.0 1.0 0.0 0.0 1.0 0.0 -0.005603485106686711\n",
      "  -0.10556140817355547 -0.1976040588580742]\n",
      " [1.0 0.0 1.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 -1.6914520043470695\n",
      "  -1.3019240341405176 -0.288225028525472]\n",
      " [0.0 1.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0 1.0 0.8061013574905347\n",
      "  0.7389298572148884 0.7841231125387299]\n",
      " [1.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 1.4304896979499357\n",
      "  1.4426725783719248 1.3731594153768123]\n",
      " [1.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0 1.0 -0.1592990766043854\n",
      "  0.4574327687520737 0.587777678259369]\n",
      " [1.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 1.0 0.0 -0.6299918255660878\n",
      "  -0.7389298572148884 -0.393949493137435]]\n",
      "X_test:\n",
      " [[0.0 1.0 1.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 -1.379257834117369\n",
      "  -1.1611754899091102 -2.553749270210404]\n",
      " [0.0 1.0 0.0 1.0 0.0 0.0 1.0 1.0 0.0 0.0 -1.5041355022092493\n",
      "  -0.08932119153146999 -1.7683675330929607]\n",
      " [0.0 1.0 0.0 1.0 0.0 1.0 0.0 0.0 1.0 0.0 0.4939071872608341\n",
      "  -0.08932119153146999 -0.0012586245787133935]]\n",
      "y_train:\n",
      " [0 1 1 1 0 0 1 0 1 1 1 1]\n",
      "y_test: [0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Display the final preprocessed data to verify our work is complete\n",
    "# These are now ready to be used by a machine learning model!\n",
    "print(f'X_train:\\n {X_train}')  # Print the scaled training features\n",
    "print(f'X_test:\\n {X_test}')  # Print the scaled testing features\n",
    "print(f'y_train:\\n {y_train}')  # Print the training target labels\n",
    "print(f'y_test: {y_test}')  # Print the testing target labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1d7c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

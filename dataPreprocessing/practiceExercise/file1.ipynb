{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1a7e69d",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f309427c",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5e2af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data processing and ML preprocessing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder , StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026df480",
   "metadata": {},
   "source": [
    "### Loading the Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f723238e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset and separate features (X) from target label (y)\n",
    "df = pd.read_csv('Data.csv')\n",
    "X = df.iloc[:,:-1].values  # All columns except the last\n",
    "y = df.iloc[:,-1].values  # Only the last column (target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4480c435",
   "metadata": {},
   "source": [
    "### Identify the missing values and handling the missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebe1997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Data:\n",
      " Country      0\n",
      "Age          1\n",
      "Salary       1\n",
      "Purchased    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values and fill them with mean strategy\n",
    "missing_data = df.isnull().sum()\n",
    "print(f'Missing Data:\\n {missing_data}')\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')  # Use average value to fill gaps\n",
    "X[:,1:3] = imputer.fit_transform(X[:,1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af37c5cd",
   "metadata": {},
   "source": [
    "#### Encoding the independent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b517dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical feature (first column) to numerical format using OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encode',OneHotEncoder(),[0])],remainder='passthrough')\n",
    "X = ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e277037",
   "metadata": {},
   "source": [
    "#### Encoding the dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01efebde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert target labels (y) from text to numbers using LabelEncoder\n",
    "lb = LabelEncoder()\n",
    "y = lb.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d7e72c",
   "metadata": {},
   "source": [
    "### Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea164049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data: 80% training (learn), 20% testing (evaluate)\n",
    "X_train, X_test , y_train , y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbad289",
   "metadata": {},
   "source": [
    "### feature Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2510f89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features from column 3 onwards to mean=0, std=1 for better model learning\n",
    "st = StandardScaler()\n",
    "\n",
    "X_train[:,3:] = st.fit_transform(X_train[:,3:])\n",
    "\n",
    "X_test[:,3:] = st.transform(X_test[:,3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af1269b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train : [[1.0 0.0 0.0 -0.7529426005471074 -0.6260377781240922]\n",
      " [1.0 0.0 0.0 1.008453807952985 1.013042950055349]\n",
      " [1.0 0.0 0.0 1.7912966561752484 1.8325833141450698]\n",
      " [0.0 1.0 0.0 -1.7314961608249366 -1.0943465576039326]\n",
      " [1.0 0.0 0.0 -0.3615211764359758 0.4276569757055486]\n",
      " [0.0 1.0 0.0 0.22561095973072173 0.05040823668012205]\n",
      " [0.0 0.0 1.0 -0.16581046438040992 -0.274806193514212]\n",
      " [0.0 0.0 1.0 -0.013591021670525248 -1.328500947343853]]\n",
      "\n",
      "X_test: [[0.0 1.0 0.0 50.00000000000001 83000.0]\n",
      " [0.0 0.0 1.0 27.000000000000004 48000.0]]\n",
      "\n",
      "y_train[1 0 1 0 1 1 0 0]\n",
      "\n",
      "y_test[0 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the final preprocessed training and testing datasets ready for model training\n",
    "print(f'X_train : {X_train}\\n')\n",
    "print(f'X_test: {X_test}\\n')\n",
    "print(f'y_train{y_train}\\n')\n",
    "print(f'y_test{y_test}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facf1b84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
